{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF Serving.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMEsUq+pW5jfNXGOCPhW5xH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ctdBxXLzKYqp"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","source":["import requests\n","# Example service that returns your IP address (server address for the Colab notebook)\n","r = requests.get('https://api.ipify.org?format=json')\n","j = r.json()\n","print(j)\n","# For ML, our server is the same but more complex in that it returns predictions from an ML model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c-NXaYIKKeq9","executionInfo":{"status":"ok","timestamp":1659135730569,"user_tz":300,"elapsed":7,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"4d7a17c6-d265-4f9d-c71b-7c3351db12a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'ip': '34.87.81.131'}\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import subprocess\n","\n","from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n","from tensorflow.keras.models import Model"],"metadata":{"id":"0XIvX3oAK_N_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fashion_mnist = tf.keras.datasets.fashion_mnist\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","print(\"x_train.shape:\", x_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R4o0Fm3xLLKM","executionInfo":{"status":"ok","timestamp":1659135732069,"user_tz":300,"elapsed":1505,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"7e000764-8e44-4255-a27c-9bc3286975cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n","x_train.shape: (60000, 28, 28)\n"]}]},{"cell_type":"code","source":["x_train = np.expand_dims(x_train, -1)\n","x_test = np.expand_dims(x_test, -1)\n","print(\"x_train.shape:\", x_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aTQbKNgfLoxe","executionInfo":{"status":"ok","timestamp":1659135732069,"user_tz":300,"elapsed":8,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"31a64032-f18c-4350-cd85-49049d05c2b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train.shape: (60000, 28, 28, 1)\n"]}]},{"cell_type":"code","source":["K = len(set(y_train))\n","print(\"number of classes:\", K)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nciiiRFMLrqg","executionInfo":{"status":"ok","timestamp":1659135732070,"user_tz":300,"elapsed":5,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"f755399e-ed19-4b9f-beb5-c06e31cfce2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["number of classes: 10\n"]}]},{"cell_type":"code","source":["# Build CNN\n","i = Input(shape=x_train[0].shape)\n","x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)\n","x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)\n","x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)\n","x = Flatten()(x)\n","x = Dropout(0.2)(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dense(K, activation='softmax')(x)\n","\n","model = Model(i, x)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HxYkgUfaL13B","executionInfo":{"status":"ok","timestamp":1659135736518,"user_tz":300,"elapsed":4452,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"377c5e3e-10e7-4c46-b860-0fb7d2310a21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 13, 13, 32)        320       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 2, 2, 128)         73856     \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               262656    \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 360,458\n","Trainable params: 360,458\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","r = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZgyIlZcMX5U","executionInfo":{"status":"ok","timestamp":1659135879089,"user_tz":300,"elapsed":142575,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"af2293ff-be1c-4af2-e393-3b392de5776a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","1875/1875 [==============================] - 18s 4ms/step - loss: 0.5055 - accuracy: 0.8120 - val_loss: 0.3863 - val_accuracy: 0.8576\n","Epoch 2/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.3486 - accuracy: 0.8670 - val_loss: 0.3364 - val_accuracy: 0.8785\n","Epoch 3/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.3001 - accuracy: 0.8868 - val_loss: 0.3100 - val_accuracy: 0.8841\n","Epoch 4/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2663 - accuracy: 0.8979 - val_loss: 0.3158 - val_accuracy: 0.8857\n","Epoch 5/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2400 - accuracy: 0.9089 - val_loss: 0.3043 - val_accuracy: 0.8913\n","Epoch 6/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2192 - accuracy: 0.9172 - val_loss: 0.3173 - val_accuracy: 0.8906\n","Epoch 7/15\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.1997 - accuracy: 0.9229 - val_loss: 0.2958 - val_accuracy: 0.8980\n","Epoch 8/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.1840 - accuracy: 0.9293 - val_loss: 0.3046 - val_accuracy: 0.8995\n","Epoch 9/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.1678 - accuracy: 0.9368 - val_loss: 0.3222 - val_accuracy: 0.8955\n","Epoch 10/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.1544 - accuracy: 0.9411 - val_loss: 0.3221 - val_accuracy: 0.9012\n","Epoch 11/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.1424 - accuracy: 0.9451 - val_loss: 0.3573 - val_accuracy: 0.8987\n","Epoch 12/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.1342 - accuracy: 0.9482 - val_loss: 0.3491 - val_accuracy: 0.8979\n","Epoch 13/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.1214 - accuracy: 0.9534 - val_loss: 0.3620 - val_accuracy: 0.9032\n","Epoch 14/15\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.1167 - accuracy: 0.9557 - val_loss: 0.3745 - val_accuracy: 0.8962\n","Epoch 15/15\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.1087 - accuracy: 0.9584 - val_loss: 0.3648 - val_accuracy: 0.8991\n"]}]},{"cell_type":"code","source":["# Save the model to a temp directory\n","# Needs to be saved to a format called protocol buffer (a standardized way of (de)serialzing objects)\n","# If its saved this way, a model saved in 1 language could be loaded in used in another language\n","import tempfile\n","\n","MODEL_DIR = tempfile.gettempdir()\n","version = 1\n","export_path = os.path.join(MODEL_DIR, str(version)) # folder: /tmp/1\n","print(\"export path:\", export_path)\n","\n","# Delete export path if it already exists\n","if os.path.isdir(export_path):\n","  print('\\nAlready saved a model, cleaning up\\n')\n","  !rm -r {export_path}\n","\n","tf.saved_model.save(model, export_path)\n","\n","print('\\nSaved model:')\n","!ls -l {export_path}\n","\n","# pb (file extension) stands for 'protocol buffer'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PN-YUFSM8_b","executionInfo":{"status":"ok","timestamp":1659136170386,"user_tz":300,"elapsed":418,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"268a8163-7ab8-4ba0-e193-ca2e07e85952"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["export path: /tmp/1\n","INFO:tensorflow:Assets written to: /tmp/1/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/1/assets\n"]},{"output_type":"stream","name":"stdout","text":["\n","Saved model:\n","total 148\n","drwxr-xr-x 2 root root   4096 Jul 29 23:09 assets\n","-rw-r--r-- 1 root root 142737 Jul 29 23:09 saved_model.pb\n","drwxr-xr-x 2 root root   4096 Jul 29 23:09 variables\n"]}]},{"cell_type":"code","source":["# Print out some info about our saved model\n","!saved_model_cli show --dir {export_path} --all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEisaQCMOdud","executionInfo":{"status":"ok","timestamp":1659136269002,"user_tz":300,"elapsed":3747,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"a3bddbfc-d020-4bb1-e7e0-b39dcb02a09b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n","\n","signature_def['__saved_model_init_op']:\n","  The given SavedModel SignatureDef contains the following input(s):\n","  The given SavedModel SignatureDef contains the following output(s):\n","    outputs['__saved_model_init_op'] tensor_info:\n","        dtype: DT_INVALID\n","        shape: unknown_rank\n","        name: NoOp\n","  Method name is: \n","\n","signature_def['serving_default']:\n","  The given SavedModel SignatureDef contains the following input(s):\n","    inputs['input_1'] tensor_info:\n","        dtype: DT_FLOAT\n","        shape: (-1, 28, 28, 1)\n","        name: serving_default_input_1:0\n","  The given SavedModel SignatureDef contains the following output(s):\n","    outputs['dense_1'] tensor_info:\n","        dtype: DT_FLOAT\n","        shape: (-1, 10)\n","        name: StatefulPartitionedCall:0\n","  Method name is: tensorflow/serving/predict\n","\n","Concrete Functions:\n","  Function Name: '__call__'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n","        Argument #2\n","          DType: bool\n","          Value: False\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #2\n","      Callable with:\n","        Argument #1\n","          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n","        Argument #2\n","          DType: bool\n","          Value: False\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #3\n","      Callable with:\n","        Argument #1\n","          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n","        Argument #2\n","          DType: bool\n","          Value: True\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #4\n","      Callable with:\n","        Argument #1\n","          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n","        Argument #2\n","          DType: bool\n","          Value: True\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","\n","  Function Name: '_default_save_signature'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n","\n","  Function Name: 'call_and_return_all_conditional_losses'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n","        Argument #2\n","          DType: bool\n","          Value: True\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #2\n","      Callable with:\n","        Argument #1\n","          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n","        Argument #2\n","          DType: bool\n","          Value: False\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #3\n","      Callable with:\n","        Argument #1\n","          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n","        Argument #2\n","          DType: bool\n","          Value: True\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #4\n","      Callable with:\n","        Argument #1\n","          input_1: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1')\n","        Argument #2\n","          DType: bool\n","          Value: False\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n"]}]},{"cell_type":"markdown","source":["Notice above the input and output info, which is correct"],"metadata":{"id":"yQeQMcwaO64T"}},{"cell_type":"code","source":["# Since notebook runs on linux machine, the usual linux commands work\n","# Add TensorFlow Serving distribution URI as a package source (one time setup) (aptitude package manager)\n","# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n","# You would instead do:\n","# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n","# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n","\n","!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n","curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n","# Install and update TensorFlow ModelServer\n","!apt update"],"metadata":{"id":"las-TDqzPnw_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt-get install tensorflow-model-server"],"metadata":{"id":"AMT23Q8dudUR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ[\"MODEL_DIR\"] = MODEL_DIR"],"metadata":{"id":"uVTXIuXsRPfM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start up the server using the command tensorflow_model_server\n","# nohub tells the program to ignore \"hang up\" and other signals, so it continues running when we close window/browser\n","%%bash --bg\n","nohup tensorflow_model_server \\\n","  --rest-api-port=8501 \\ # send port to 8501\n","  --model_name=fashion_model \\ # whats our model named?\n","  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1 # outputs of program will be written to /tmp/1/server.log"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlgxMXgNRUx-","executionInfo":{"status":"ok","timestamp":1659137094695,"user_tz":300,"elapsed":2,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"39480def-29bf-47e9-abbd-345a9a1cb402"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting job # 0 in a separate thread.\n"]}]},{"cell_type":"code","source":["!tail server.log"],"metadata":{"id":"sVy_NfzcRu5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now that server is running, make some requests in python to this server\n","# In reality, client and server would be on different machine\n","labels = '''T-shirt/top\n","Trouser\n","Pullover\n","Dress\n","Coat\n","Sandal\n","Shirt\n","Sneaker\n","Bag\n","Ankle boot'''.split(\"\\n\")"],"metadata":{"id":"4IQh401GSgxR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot a random sample from our test set\n","def show(idx, title):\n","  plt.figure()\n","  plt.imshow(x_test[idx].reshape(28,28), cmap='gray')\n","  plt.axis('off')\n","  plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})\n","\n","i = np.random.randint(0, len(x_test))\n","show(i, labels[y_test[i]])"],"metadata":{"id":"BP__vS6rSwjB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Format some data to pass to the server (how to use the API)\n","'''\n","{\n","  \"signature_name\": \"serving_default\",\n","  \"instances\": [an N x H x W x C list]\n","}\n","'''\n","import json\n","data = json.dumps({ # dumps = object -> string\n","    \"signature_name\": \"serving_default\",\n","    \"instances\": x_test[0:3].tolist() # convert numpy array to list since json cant represent numpy array\n","})"],"metadata":{"id":"XxnVxD0ZTQTw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make HTTP request. Its a POST not a GET since we're sending input data for predictions\n","headers = {\"content_type\": \"application/json\"}\n","# FINISH THIS LINE WITH REQUESTED CODE\n","r = requests.post('http://localhost:8501/v1/models/fashion_model:predict', data=data, headers)\n","j = r.json()\n","# Printing the keys is not as overwhelming especially if many keys\n","print(j.keys())\n","print(j)\n","# The json has 1 key which is 'predictions', with value being an array of predictions\n","# Not so obvious what these predictions mean"],"metadata":{"id":"Y6Dm49sMT7-X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert predictions to numpy array to check shape\n","pred = np.array(j['predictions'])\n","print(pred.shape)\n","# This is the N x K output array from the model\n","# pred[n,k] is the probability that we believe the nth sample belongs to the kth class"],"metadata":{"id":"FFeDHtzuU8zu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the predicted classes (by taking the argmax over the columns)\n","pred = pred.argmax(axis=1)"],"metadata":{"id":"lA66BJ3vVX1j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Since they are numbers, lets convert them back to strings (labels)\n","pred = [labels[i] for i in pred]\n","print(pred)"],"metadata":{"id":"QwePzxnzVgTc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the true labels\n","actual = [labels[i] for i in y_test[:3]]\n","print(actual)"],"metadata":{"id":"EoFGrQrgVq5g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(0,3):\n","  show(i, f\"True: {actual[i]}, Predicted: {pred[i]}\")"],"metadata":{"id":"xavZJzx3VzpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Another method of calling API: versioning\n","# Can have multiple models running simulataneously, e.g. during an A/B test\n","# FINISH THIS LINE WITH REQUESTED CODE\n","r = requests.post('http://localhost:8501/v1/models/fashion_model/versions/1:predict', data=data, headers)\n","headers = {\"content_type\": \"application/json\"}\n","j = r.json()\n","pred = np.array(j['predictions'])\n","pred = pred.argmax(axis=1)\n","pred = [labels[i] for i in pred]\n","for i in range(0,3):\n","  show(i, f\"True: {actual[i]}, Predicted: {pred[i]}\")"],"metadata":{"id":"7IPw_5-tWAPa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- If you trained a new model later in this script and saved it to /tmp/2 (as version 2), you would not need to restart, i.e. TensorFlow would know about it\n","- If you tried a request for a server that didnt exist, youd get 'error': 'Servable not found for request'\n","- Be default, TF uses the most up-to-date/newly released version of the model if you dont specify the version in the request\n","- DevOps people would be responsible for getting this onto an actual production environment like EC2 or GCP, using Docker, Kubernetes, Nginx, Unicorn, etc. SWE people (backend) would do the requesting (like in this code), and the ML people would create, test, and adjust the ML model (also like in this code)\n","- GCP has special tooling for Tensorflow serving"],"metadata":{"id":"d_9nGdWlXQ6V"}}]}