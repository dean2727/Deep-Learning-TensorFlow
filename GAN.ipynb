{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMpu1CxuAXev6Bhqblu19df"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"U3UiqhvMyId4","executionInfo":{"status":"ok","timestamp":1658944488121,"user_tz":300,"elapsed":3,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}}},"outputs":[],"source":["import tensorflow as tf\n","# leaky relu and batch normalization often used with GANs\n","from tensorflow.keras.layers import Input, Dense, LeakyReLU, Dropout, BatchNormalization\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import SGD, Adam\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import sys, os"]},{"cell_type":"code","source":["# Load in the data\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Map inputs to (-1, +1) for better training\n","x_train, x_test = x_train / 255.0 * 2 - 1, x_test / 255.0 * 2 - 1\n","print(\"x_train.shape:\", x_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGUpGFyQyiDG","executionInfo":{"status":"ok","timestamp":1658944485693,"user_tz":300,"elapsed":865,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"9562f10a-5b42-4a99-d948-34dfd053d8d6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","x_train.shape: (60000, 28, 28)\n"]}]},{"cell_type":"code","source":["# Flatten the data to be tabular\n","N, H, W = x_train.shape\n","D = H * W\n","x_train = x_train.reshape(-1, D)\n","x_test = x_test.reshape(-1, D)"],"metadata":{"id":"uUi0VNh0zBbI","executionInfo":{"status":"ok","timestamp":1658944533369,"user_tz":300,"elapsed":344,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Dimensionality of the latent space (hyperparameter)\n","latent_dim = 100"],"metadata":{"id":"2bBzD_EszLXs","executionInfo":{"status":"ok","timestamp":1658945290047,"user_tz":300,"elapsed":388,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Get the generator model. Takes a vector from the latent space\n","# Generator (first part of GAN) takes noise and turns it into images (reverse CNN)\n","def build_generator(latent_dim):\n","  i = Input(shape=(latent_dim,))\n","  x = Dense(256, activation=LeakyReLU(alpha=0.2))(i)\n","  x = BatchNormalization(momentum=0.8)(x)\n","  x = Dense(512, activation=LeakyReLU(alpha=0.2))(x)\n","  x = BatchNormalization(momentum=0.8)(x)\n","  x = Dense(1024, activation=LeakyReLU(alpha=0.2))(x)\n","  x = BatchNormalization(momentum=0.8)(x)\n","  x = Dense(D, activation='tanh')(x) # tanh since pixels are centered around (-1, +1)\n","\n","  model = Model(i, x)\n","  return model"],"metadata":{"id":"-Q3Cq7obzYGz","executionInfo":{"status":"ok","timestamp":1658944946576,"user_tz":300,"elapsed":355,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Get the discriminator model\n","# Discriminator (second part of GAN) is responsible for discriminating real images from fake ones\n","def build_discriminator(img_size):\n","  i = Input(shape=(img_size,))\n","  x = Dense(512, activation=LeakyReLU(alpha=0.2))(i)\n","  x = Dense(256, activation=LeakyReLU(alpha=0.2))(x)\n","  x = Dense(1, activation='sigmoid')(x) # binary classification (real or fake) -> sigmoid\n","\n","  model = Model(i, x)\n","  return model"],"metadata":{"id":"0iZdDDCR0AOV","executionInfo":{"status":"ok","timestamp":1658944949185,"user_tz":300,"elapsed":4,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Compile both models in preparation for training\n","\n","# Build and compile discriminator\n","discriminator = build_discriminator(D)\n","discriminator.compile(\n","    loss='binary_crossentropy',\n","    optimizer=Adam(0.0002, 0.5),\n","    metrics=['accuracy']\n",")\n","\n","# Build and compile the combined model\n","generator = build_generator(latent_dim)\n","\n","# Create an input to represent noise sample from latent space\n","z = Input(shape=(latent_dim,))\n","\n","# Pass noise through generator to get an image\n","img = generator(z)\n","\n","# Make sure only the generator is trained (freeze weights of discriminator)\n","discriminator.trainable = False\n","\n","# The true output is fake, but we label them real\n","fake_pred = discriminator(img)\n","\n","# Create the combined model object\n","combined_model = Model(z, fake_pred)\n","\n","# Compile combined model (flip the labels during training later)\n","combined_model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))"],"metadata":{"id":"fvGiuqZ20xI9","executionInfo":{"status":"ok","timestamp":1658945293221,"user_tz":300,"elapsed":4,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Train the GAN\n","\n","# Config\n","batch_size = 32\n","epochs = 30000\n","sample_period = 200 # generate a sample every 200 steps\n","\n","# Create batch labels to use when calling train_on_batch (so we dont make it over and over in the loop later)\n","ones = np.ones(batch_size)\n","zeros = np.zeros(batch_size)\n","\n","# Store the losses\n","d_losses, g_losses = [], []\n","\n","# Create a folder to store generated images\n","if not os.path.exists('gan_images'):\n","  os.makedirs('gan_images')"],"metadata":{"id":"Kqtdxe5w2FF6","executionInfo":{"status":"ok","timestamp":1658946708533,"user_tz":300,"elapsed":1287,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Generate a grid of random samples from the generator and save them to a file\n","def sample_images(epoch):\n","  rows, cols = 5, 5 # 25 images total\n","  # Generator noise vectors from the latent space\n","  noise = np.random.randn(rows * cols, latent_dim) # output is size 25 x 100\n","  imgs = generator.predict(noise) # get our 25 generated samples/images\n","\n","  # Rescale images to 0 - 1\n","  imgs = 0.5 * imgs + 0.5\n","\n","  fig, axs = plt.subplots(rows, cols)\n","  idx = 0\n","  for i in range(rows):\n","    for j in range(cols):\n","      axs[i,j].imshow(imgs[idx].reshape(H, W), cmap='gray')\n","      axs[i,j].axis('off') # so we dont see lines in the plots\n","  fig.savefig(\"gan_images/%d.png\" % epoch)\n","  plt.close() # cleanup resources"],"metadata":{"id":"XyqrRAJo2n93","executionInfo":{"status":"ok","timestamp":1658945870957,"user_tz":300,"elapsed":407,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Main training loop (alternate between the 2 parts of the GAN)\n","for epoch in range(epochs):\n","  # ~~~ TRAIN DISCRIMINATOR ~~~\n","\n","  # Need real and fake images. Select random batch of real images\n","  idx = np.random.randint(0, x_train.shape[0], batch_size) # random indices from 0 to # of training samples\n","  real_imgs = x_train[idx]\n","\n","  # Generate fake images (using noise sampled from the standard normal of the latent space)\n","  noise = np.random.randn(batch_size, latent_dim) # 32 x 100\n","  fake_imgs = generator.predict(noise)\n","\n","  # Train it. Both loss and accuracy are returned\n","  d_loss_real, d_acc_real = discriminator.train_on_batch(real_imgs, ones)\n","  d_loss_fake, d_acc_fake = discriminator.train_on_batch(fake_imgs, zeros)\n","  # To get overall loss and accuracy, take mean of these losses and accuracies\n","  d_loss = .5 * (d_loss_real + d_loss_fake)\n","  d_acc = .5 * (d_acc_real + d_acc_fake)\n","\n","  # ~~~ TRAIN GENERATOR ~~~\n","\n","  noise = np.random.randn(batch_size, latent_dim)\n","  # Input is noise and target is vector of ones, because we want to trick discriminator into thinking images from generator are real\n","  g_loss = combined_model.train_on_batch(noise, ones)\n","\n","  # Save the losses\n","  d_losses.append(d_loss)\n","  g_losses.append(g_loss)\n","\n","  # Print epoch info every 100 epochs\n","  if epochs % 100 == 0:\n","    print(f\"epoch: {epoch+1}/{epochs}, d_loss: {d_loss:.2f}, d_acc: {d_acc:.2f}, g_loss: {g_loss:.2f}\")\n","  \n","  # If we're on sample period, generate more random images\n","  if epoch % sample_period == 0:\n","    sample_images(epoch)\n","\n","# Note: this takes a while to train, but here are some notes from the video:\n","# For accuracy, we see that despite discriminator training, it never reaches high accuracy.\n","# This is because the generator improved as the discriminator does, which is what we want (GAN should generate realistic images)\n","# For loss, both hover around the same point throughout training because generator and discriminator feed off each other and approve in tandom"],"metadata":{"id":"r2YJnj494SDw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(g_losses, label='g_losses')\n","plt.plot(d_losses, label='d_losses')\n","plt.legend()"],"metadata":{"id":"dIOAS_np77aF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# See image files created (file name = epoch number)\n","!ls gan_images"],"metadata":{"id":"vwt_FV5K8aC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot images, during early and later epochs\n","from skimage.io import imread\n","a = imread('gan_images/0.png')\n","plt.imshow(a)"],"metadata":{"id":"bQ8IvGNp8j97"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = imread('gan_images/1000.png')\n","plt.imshow(a)"],"metadata":{"id":"wzvAyT2_8xS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = imread('gan_images/5000.png')\n","plt.imshow(a)"],"metadata":{"id":"dW1CSHD385oz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1/3 of the way through (things already look pretty good -> diminishing returns)\n","a = imread('gan_images/10000.png')\n","plt.imshow(a)"],"metadata":{"id":"HqfDwel68754"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2/3 of the way through\n","a = imread('gan_images/20000.png')\n","plt.imshow(a)"],"metadata":{"id":"Eu7bOSen88wH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = imread('gan_images/29000.png')\n","plt.imshow(a)"],"metadata":{"id":"ew89veFA89lB"},"execution_count":null,"outputs":[]}]}