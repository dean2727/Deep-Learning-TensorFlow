{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text preprocessing.ipynb","provenance":[],"authorship_tag":"ABX9TyOLyhxYPqQuUSVrFpmH4Wsf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"yxZDlnjMQJdy","executionInfo":{"status":"ok","timestamp":1658801275324,"user_tz":300,"elapsed":6052,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","source":["# Just simple test\n","sentences = [\n","  \"I like eggs and ham.\",\n","  \"I love chocolate and bunnies.\",\n","  \"I hate onions.\"             \n","]"],"metadata":{"id":"9TskSGFmQppt","executionInfo":{"status":"ok","timestamp":1658801298513,"user_tz":300,"elapsed":3,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# This is usually a pretty reasonable size\n","# 3000 words is about 95% of most text, so 20000 should be fine\n","# everything outside 20000 is assigned a <RARE> token (same value)\n","MAX_VOCAB_SIZE = 20000\n","tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n","# First, sentences is an iterable, where each sentence is a string\n","tokenizer.fit_on_texts(sentences) # akin to fit() from sklearn\n","# Then, convert iterable of sentences to corresponding list of integers\n","sequences = tokenizer.texts_to_sequences(sentences) # akin to transform() from sklearn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"pUXITRPoQx2V","executionInfo":{"status":"ok","timestamp":1658801648489,"user_tz":300,"elapsed":416,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"bdefe8c5-0d2d-4244-c419-df4dcb1f3000"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ne.g. sentences now looks like this:\\nsentences = [\\n  [1,2,3,4,5],\\n  [1,6,7,4,8],\\n  [1,9,10]\\n]\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["print(sequences) # (dont run this for some huge dataset)\n","# Notice how it counts from 1, since TF uses 0 for padding value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQaafL0zSHGZ","executionInfo":{"status":"ok","timestamp":1658801656525,"user_tz":300,"elapsed":223,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"f8c419ab-7f6f-4e31-fb1e-dd214f39badb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1, 3, 4, 2, 5], [1, 6, 7, 2, 8], [1, 9, 10]]\n"]}]},{"cell_type":"code","source":["# tokenizer stores a dict which maps index to word\n","tokenizer.word_index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zSj_8fOvSTiO","executionInfo":{"status":"ok","timestamp":1658801712880,"user_tz":300,"elapsed":233,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"644ad593-0be7-4739-9041-083e11361eef"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'and': 2,\n"," 'bunnies': 8,\n"," 'chocolate': 7,\n"," 'eggs': 4,\n"," 'ham': 5,\n"," 'hate': 9,\n"," 'i': 1,\n"," 'like': 3,\n"," 'love': 6,\n"," 'onions': 10}"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["data = pad_sequences(sequences)\n","print(data)\n","# max length = 5, and padding at beginning for default"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOwBTaLrSajU","executionInfo":{"status":"ok","timestamp":1658801745444,"user_tz":300,"elapsed":4,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"fe383ca0-fd8a-49d0-ad34-2218d17330e0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1  3  4  2  5]\n"," [ 1  6  7  2  8]\n"," [ 0  0  1  9 10]]\n"]}]},{"cell_type":"code","source":["# passing in max length and set padding to post\n","MAX_SEQUENCE_LENGTH = 5\n","data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post') # 'pre' is default\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jq4rI2M7Sjoi","executionInfo":{"status":"ok","timestamp":1658801809178,"user_tz":300,"elapsed":253,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"53c340ef-cd18-4fe9-cc6e-ce8a61418817"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1  3  4  2  5]\n"," [ 1  6  7  2  8]\n"," [ 1  9 10  0  0]]\n"]}]},{"cell_type":"markdown","source":["Scenario to use pre padding: classifying spam or not span (minimize likelihood of forgetting previous values)\n","\n","Scenario to use post padding: neural machine translation (if language B has longer sentence than language A, we dont want language B to be at a loss at the beginning of the sentence)"],"metadata":{"id":"Ei9xDxx2S4Mb"}},{"cell_type":"code","source":["# too much padding\n","data = pad_sequences(sequences, maxlen=6)\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"em0tYXu4TNN2","executionInfo":{"status":"ok","timestamp":1658801953767,"user_tz":300,"elapsed":8,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"dd343993-eb9f-4b0c-c9cc-4d05c98aa695"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  1  3  4  2  5]\n"," [ 0  1  6  7  2  8]\n"," [ 0  0  0  1  9 10]]\n"]}]},{"cell_type":"code","source":["# truncation\n","data = pad_sequences(sequences, maxlen=4)\n","print(data)\n","# BEGINNING is cutoff (makes sense, cause RNN pays attention to final values more)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2YievyrmTS0f","executionInfo":{"status":"ok","timestamp":1658801971259,"user_tz":300,"elapsed":242,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"5cc3735a-24de-43a7-e913-86f58aaa668d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 3  4  2  5]\n"," [ 6  7  2  8]\n"," [ 0  1  9 10]]\n"]}]},{"cell_type":"code","source":["# truncate at the end\n","data = pad_sequences(sequences, maxlen=4, truncating='post') # default is 'pre'\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7iJ7cK-tTcAK","executionInfo":{"status":"ok","timestamp":1658802015117,"user_tz":300,"elapsed":230,"user":{"displayName":"Dean Orenstein","userId":"15720196102026995887"}},"outputId":"9b5e804d-118c-4a7c-c520-878db1db9ab9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1  3  4  2]\n"," [ 1  6  7  2]\n"," [ 0  1  9 10]]\n"]}]}]}