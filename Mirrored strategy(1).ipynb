{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mirrored strategy.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOPDboPmmYQ7+4KEmZjFTIG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FZyr1VvB0DUD"},"outputs":[],"source":["# Google is the king of distributed computing, and they have multiple \"distributed strategies\" to split up work when it comes to training on very large datasets\n","# We shall go through one strategy here, the mirrored strategy (multiple GPUs, one machine)\n","import tensorflow as tf"]}]}